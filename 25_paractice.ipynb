{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Prepare Problem <br>\n",
    "a) Load libraries\n",
    "b) Load dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('datasets/housing.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 14)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.320e-03, 1.800e+01, 2.310e+00, 0.000e+00, 5.380e-01, 6.575e+00,\n",
       "       6.520e+01, 4.090e+00, 1.000e+00, 2.960e+02, 1.530e+01, 3.969e+02,\n",
       "       4.980e+00, 2.400e+01])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:, :13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "        4.9800e+00],\n",
       "       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "        9.1400e+00],\n",
       "       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "        4.0300e+00],\n",
       "       ...,\n",
       "       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        5.6400e+00],\n",
       "       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "        6.4800e+00],\n",
       "       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        7.8800e+00]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[:, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Summarize Data <br>\n",
    "a) Descriptive statistics\n",
    "b) Data visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2, svd_solver='randomized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(X)\n",
    "X_train_pca = pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1])\n",
    "plt.xlabel(\"X0\")\n",
    "plt.ylabel(\"X1\")\n",
    "plt.title('Dataset Visualization')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "               6           7           8           9           10          11  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "               12  \n",
       "count  506.000000  \n",
       "mean    12.653063  \n",
       "std      7.141062  \n",
       "min      1.730000  \n",
       "25%      6.950000  \n",
       "50%     11.360000  \n",
       "75%     16.955000  \n",
       "max     37.970000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.200469</td>\n",
       "      <td>0.406583</td>\n",
       "      <td>-0.055892</td>\n",
       "      <td>0.420972</td>\n",
       "      <td>-0.219247</td>\n",
       "      <td>0.352734</td>\n",
       "      <td>-0.379670</td>\n",
       "      <td>0.625505</td>\n",
       "      <td>0.582764</td>\n",
       "      <td>0.289946</td>\n",
       "      <td>-0.385064</td>\n",
       "      <td>0.455621</td>\n",
       "      <td>-0.388305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.200469</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.533828</td>\n",
       "      <td>-0.042697</td>\n",
       "      <td>-0.516604</td>\n",
       "      <td>0.311991</td>\n",
       "      <td>-0.569537</td>\n",
       "      <td>0.664408</td>\n",
       "      <td>-0.311948</td>\n",
       "      <td>-0.314563</td>\n",
       "      <td>-0.391679</td>\n",
       "      <td>0.175520</td>\n",
       "      <td>-0.412995</td>\n",
       "      <td>0.360445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.406583</td>\n",
       "      <td>-0.533828</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.062938</td>\n",
       "      <td>0.763651</td>\n",
       "      <td>-0.391676</td>\n",
       "      <td>0.644779</td>\n",
       "      <td>-0.708027</td>\n",
       "      <td>0.595129</td>\n",
       "      <td>0.720760</td>\n",
       "      <td>0.383248</td>\n",
       "      <td>-0.356977</td>\n",
       "      <td>0.603800</td>\n",
       "      <td>-0.483725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.055892</td>\n",
       "      <td>-0.042697</td>\n",
       "      <td>0.062938</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.091203</td>\n",
       "      <td>0.091251</td>\n",
       "      <td>0.086518</td>\n",
       "      <td>-0.099176</td>\n",
       "      <td>-0.007368</td>\n",
       "      <td>-0.035587</td>\n",
       "      <td>-0.121515</td>\n",
       "      <td>0.048788</td>\n",
       "      <td>-0.053929</td>\n",
       "      <td>0.175260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.420972</td>\n",
       "      <td>-0.516604</td>\n",
       "      <td>0.763651</td>\n",
       "      <td>0.091203</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.302188</td>\n",
       "      <td>0.731470</td>\n",
       "      <td>-0.769230</td>\n",
       "      <td>0.611441</td>\n",
       "      <td>0.668023</td>\n",
       "      <td>0.188933</td>\n",
       "      <td>-0.380051</td>\n",
       "      <td>0.590879</td>\n",
       "      <td>-0.427321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.219247</td>\n",
       "      <td>0.311991</td>\n",
       "      <td>-0.391676</td>\n",
       "      <td>0.091251</td>\n",
       "      <td>-0.302188</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.240265</td>\n",
       "      <td>0.205246</td>\n",
       "      <td>-0.209847</td>\n",
       "      <td>-0.292048</td>\n",
       "      <td>-0.355501</td>\n",
       "      <td>0.128069</td>\n",
       "      <td>-0.613808</td>\n",
       "      <td>0.695360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.352734</td>\n",
       "      <td>-0.569537</td>\n",
       "      <td>0.644779</td>\n",
       "      <td>0.086518</td>\n",
       "      <td>0.731470</td>\n",
       "      <td>-0.240265</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.747881</td>\n",
       "      <td>0.456022</td>\n",
       "      <td>0.506456</td>\n",
       "      <td>0.261515</td>\n",
       "      <td>-0.273534</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>-0.376955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.379670</td>\n",
       "      <td>0.664408</td>\n",
       "      <td>-0.708027</td>\n",
       "      <td>-0.099176</td>\n",
       "      <td>-0.769230</td>\n",
       "      <td>0.205246</td>\n",
       "      <td>-0.747881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.494588</td>\n",
       "      <td>-0.534432</td>\n",
       "      <td>-0.232471</td>\n",
       "      <td>0.291512</td>\n",
       "      <td>-0.496996</td>\n",
       "      <td>0.249929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.625505</td>\n",
       "      <td>-0.311948</td>\n",
       "      <td>0.595129</td>\n",
       "      <td>-0.007368</td>\n",
       "      <td>0.611441</td>\n",
       "      <td>-0.209847</td>\n",
       "      <td>0.456022</td>\n",
       "      <td>-0.494588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910228</td>\n",
       "      <td>0.464741</td>\n",
       "      <td>-0.444413</td>\n",
       "      <td>0.488676</td>\n",
       "      <td>-0.381626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.582764</td>\n",
       "      <td>-0.314563</td>\n",
       "      <td>0.720760</td>\n",
       "      <td>-0.035587</td>\n",
       "      <td>0.668023</td>\n",
       "      <td>-0.292048</td>\n",
       "      <td>0.506456</td>\n",
       "      <td>-0.534432</td>\n",
       "      <td>0.910228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.460853</td>\n",
       "      <td>-0.441808</td>\n",
       "      <td>0.543993</td>\n",
       "      <td>-0.468536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.289946</td>\n",
       "      <td>-0.391679</td>\n",
       "      <td>0.383248</td>\n",
       "      <td>-0.121515</td>\n",
       "      <td>0.188933</td>\n",
       "      <td>-0.355501</td>\n",
       "      <td>0.261515</td>\n",
       "      <td>-0.232471</td>\n",
       "      <td>0.464741</td>\n",
       "      <td>0.460853</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.177383</td>\n",
       "      <td>0.374044</td>\n",
       "      <td>-0.507787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.385064</td>\n",
       "      <td>0.175520</td>\n",
       "      <td>-0.356977</td>\n",
       "      <td>0.048788</td>\n",
       "      <td>-0.380051</td>\n",
       "      <td>0.128069</td>\n",
       "      <td>-0.273534</td>\n",
       "      <td>0.291512</td>\n",
       "      <td>-0.444413</td>\n",
       "      <td>-0.441808</td>\n",
       "      <td>-0.177383</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.366087</td>\n",
       "      <td>0.333461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.455621</td>\n",
       "      <td>-0.412995</td>\n",
       "      <td>0.603800</td>\n",
       "      <td>-0.053929</td>\n",
       "      <td>0.590879</td>\n",
       "      <td>-0.613808</td>\n",
       "      <td>0.602339</td>\n",
       "      <td>-0.496996</td>\n",
       "      <td>0.488676</td>\n",
       "      <td>0.543993</td>\n",
       "      <td>0.374044</td>\n",
       "      <td>-0.366087</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.737663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.388305</td>\n",
       "      <td>0.360445</td>\n",
       "      <td>-0.483725</td>\n",
       "      <td>0.175260</td>\n",
       "      <td>-0.427321</td>\n",
       "      <td>0.695360</td>\n",
       "      <td>-0.376955</td>\n",
       "      <td>0.249929</td>\n",
       "      <td>-0.381626</td>\n",
       "      <td>-0.468536</td>\n",
       "      <td>-0.507787</td>\n",
       "      <td>0.333461</td>\n",
       "      <td>-0.737663</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0   1.000000 -0.200469  0.406583 -0.055892  0.420972 -0.219247  0.352734   \n",
       "1  -0.200469  1.000000 -0.533828 -0.042697 -0.516604  0.311991 -0.569537   \n",
       "2   0.406583 -0.533828  1.000000  0.062938  0.763651 -0.391676  0.644779   \n",
       "3  -0.055892 -0.042697  0.062938  1.000000  0.091203  0.091251  0.086518   \n",
       "4   0.420972 -0.516604  0.763651  0.091203  1.000000 -0.302188  0.731470   \n",
       "5  -0.219247  0.311991 -0.391676  0.091251 -0.302188  1.000000 -0.240265   \n",
       "6   0.352734 -0.569537  0.644779  0.086518  0.731470 -0.240265  1.000000   \n",
       "7  -0.379670  0.664408 -0.708027 -0.099176 -0.769230  0.205246 -0.747881   \n",
       "8   0.625505 -0.311948  0.595129 -0.007368  0.611441 -0.209847  0.456022   \n",
       "9   0.582764 -0.314563  0.720760 -0.035587  0.668023 -0.292048  0.506456   \n",
       "10  0.289946 -0.391679  0.383248 -0.121515  0.188933 -0.355501  0.261515   \n",
       "11 -0.385064  0.175520 -0.356977  0.048788 -0.380051  0.128069 -0.273534   \n",
       "12  0.455621 -0.412995  0.603800 -0.053929  0.590879 -0.613808  0.602339   \n",
       "13 -0.388305  0.360445 -0.483725  0.175260 -0.427321  0.695360 -0.376955   \n",
       "\n",
       "          7         8         9         10        11        12        13  \n",
       "0  -0.379670  0.625505  0.582764  0.289946 -0.385064  0.455621 -0.388305  \n",
       "1   0.664408 -0.311948 -0.314563 -0.391679  0.175520 -0.412995  0.360445  \n",
       "2  -0.708027  0.595129  0.720760  0.383248 -0.356977  0.603800 -0.483725  \n",
       "3  -0.099176 -0.007368 -0.035587 -0.121515  0.048788 -0.053929  0.175260  \n",
       "4  -0.769230  0.611441  0.668023  0.188933 -0.380051  0.590879 -0.427321  \n",
       "5   0.205246 -0.209847 -0.292048 -0.355501  0.128069 -0.613808  0.695360  \n",
       "6  -0.747881  0.456022  0.506456  0.261515 -0.273534  0.602339 -0.376955  \n",
       "7   1.000000 -0.494588 -0.534432 -0.232471  0.291512 -0.496996  0.249929  \n",
       "8  -0.494588  1.000000  0.910228  0.464741 -0.444413  0.488676 -0.381626  \n",
       "9  -0.534432  0.910228  1.000000  0.460853 -0.441808  0.543993 -0.468536  \n",
       "10 -0.232471  0.464741  0.460853  1.000000 -0.177383  0.374044 -0.507787  \n",
       "11  0.291512 -0.444413 -0.441808 -0.177383  1.000000 -0.366087  0.333461  \n",
       "12 -0.496996  0.488676  0.543993  0.374044 -0.366087  1.000000 -0.737663  \n",
       "13  0.249929 -0.381626 -0.468536 -0.507787  0.333461 -0.737663  1.000000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data).corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Prepare Data  <br>\n",
    "a) Data Cleaning\n",
    "b) Feature Selection\n",
    "c) Data Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# highest correlation with output\n",
    "X = X[:, (1,3,5,7,11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 5)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Rescale data (between 0 and 1)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "scaler = scaler.fit(X_train)\n",
    "rescaled_X_train = scaler.transform(X_train)\n",
    "rescaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Evaluate Algorithms <br>\n",
    "a) Split-out validation dataset\n",
    "b) Test options and evaluation metric\n",
    "c) Spot Check Algorithms\n",
    "d) Compare Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "lr = LinearRegression()\n",
    "knn = KNeighborsRegressor()\n",
    "dt = DecisionTreeRegressor()\n",
    "svm = SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "kfold = KFold(n_splits=5, random_state=42)\n",
    "\n",
    "results_lr = cross_val_score(lr, rescaled_X_train, y_train, cv=kfold, scoring=\"neg_mean_squared_error\")\n",
    "results_knn = cross_val_score(knn, rescaled_X_train, y_train, cv=kfold, scoring=\"neg_mean_squared_error\")\n",
    "results_dt = cross_val_score(dt, rescaled_X_train, y_train, cv=kfold, scoring=\"neg_mean_squared_error\")\n",
    "results_svm = cross_val_score(svm, rescaled_X_train, y_train, cv=kfold, scoring=\"neg_mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:  36.963634847059346\n",
      "KNN:  31.92768456790124\n",
      "Decision Tree:  54.347305246913585\n",
      "SVM 45.68750326357371\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear Regression: \", -results_lr.mean())\n",
    "print(\"KNN: \", -results_knn.mean())\n",
    "print(\"Decision Tree: \", -results_dt.mean())\n",
    "print(\"SVM\", -results_svm.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Improve Accuracy <br>\n",
    "a) Algorithm Tuning\n",
    "b) Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "k = np.array([1, 3, 7, 9])\n",
    "param_grid = dict(n_neighbors=k)\n",
    "\n",
    "model = KNeighborsRegressor()\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid.fit(rescaled_X_train, y_train)\n",
    "print(grid.best_estimator_.n_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN:  31.712041194177722\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=grid.best_estimator_.n_neighbors)\n",
    "results_knn = cross_val_score(knn, rescaled_X_train, y_train, cv=kfold, scoring=\"neg_mean_squared_error\")\n",
    "print(\"KNN: \", -results_knn.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.190155246913584\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "results = cross_val_score(xgb, rescaled_X_train, y_train, cv=kfold, scoring=\"neg_mean_squared_error\")\n",
    "print(-results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Finalize Model <br>\n",
    "a) Predictions on validation dataset\n",
    "b) Create standalone model on entire training dataset\n",
    "c) Save model for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                    metric_params=None, n_jobs=None, n_neighbors=9, p=2,\n",
       "                    weights='uniform')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=grid.best_estimator_.n_neighbors)\n",
    "knn.fit(rescaled_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = knn.predict(rescaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.64403050108933"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mean_squared_error(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4923747276688455"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk with pickle\n",
    "from pickle import dump\n",
    "\n",
    "filename = 'knn_reg.sav'\n",
    "dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
